{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this article, I will explain how to develop an Automated Supervised Machine Learning Regression program, which automatically tunes the hyperparameters and prints out the final results as tables, graphs and boxplots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I always like to keep my libraries together, hence I import all of them at once in the beginning of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets import our dataset and define the features and the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing datasets\n"
     ]
    }
   ],
   "source": [
    "#Importing the datasets-------------------------------------------------------\n",
    "print (\"Importing datasets\")\n",
    "df = pd.read_csv('data.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how the dataset looks. I like using df.describe() function to have some statistics about each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25.330330</td>\n",
       "      <td>25.052052</td>\n",
       "      <td>24.791792</td>\n",
       "      <td>24.837838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.690016</td>\n",
       "      <td>14.494809</td>\n",
       "      <td>14.485799</td>\n",
       "      <td>15.160588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                A           B           C           D\n",
       "count  999.000000  999.000000  999.000000  999.000000\n",
       "mean    25.330330   25.052052   24.791792   24.837838\n",
       "std     14.690016   14.494809   14.485799   15.160588\n",
       "min      0.000000    0.000000    0.000000    0.000000\n",
       "25%     13.000000   13.000000   12.000000   12.000000\n",
       "50%     25.000000   25.000000   24.000000   25.000000\n",
       "75%     38.000000   37.000000   37.000000   38.000000\n",
       "max     50.000000   50.000000   50.000000   50.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As illustrated, this is a dataset with random points, which has a maximum value of 50 and minimum 0 in all columns. This is a 999x4 data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the features as X and the column we want to predict (column D) as y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1].values \n",
    "y = df.iloc[:,3].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines X as all the values except the last column (columns A,B and C), and y as the last column (column numbers start from zero, hence: 0 - A, 1 - B, 2 - C, 3 - D)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some algorithms we might want to use X as preprocessed (normalized) values (X2). This mostly provides higher accuracies for algorithms such as Multi Layer Perceptron (MLP) or Support Vector Machines (SVM). Hence, for the rest of the program, X2 will be used for non-linear ML algorithms such as random forest, XGBoost, MLP, SVM. However, X will be used for polynomial regressions and linear regression to evaluate the regression constants easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to split our dataset as train and test data. For this we can use train_test_split by sklearn.model_selection. We will do this for both X and X2. Test size of 0.20 means that 20% of the data will be used as test data and 80% of the data will be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X,y,test_size = 0.20)\n",
    "X_train2, X_test2, y_train2, y_test2= train_test_split(X2,y,test_size = 0.20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might not always want to tune the parameters of models, or only tune for some models. For this I have defined basic inputs. When they are set to \"yes\", the program will perform the tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs------------------------------------------------------------------------\n",
    "randomforestparametertuning = \"yes\"\n",
    "XGboostparametertuning = \"yes\"\n",
    "SVMparametertuning =\"yes\"\n",
    "MLPparametertuning =\"yes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first one is training, testing and tuning the random forest regression. The values of param_grid might be updated regarding the problem (i.e., some problems might require higher values of n_estimators, while some might require lower ranges)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing gridsearch in random forest\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 972 out of 972 | elapsed:  4.0min finished\n"
     ]
    }
   ],
   "source": [
    "if randomforestparametertuning == \"yes\":\n",
    "    print (\"Performing gridsearch in random forest\")\n",
    "\n",
    "    # Create the parameter grid based on the results of random search \n",
    "    param_grid = {\n",
    "        'bootstrap': [True,False],\n",
    "        'max_depth': [40, 50, 60],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'min_samples_leaf': [1,2,3,],\n",
    "        'min_samples_split': [3,4,5],\n",
    "        'n_estimators': [100, 200, 300]\n",
    "    }\n",
    "    # Create a based model\n",
    "    rf = RandomForestRegressor()\n",
    "    # Instantiate the grid search model\n",
    "    grid_search_RF = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                              cv = 3, n_jobs = -1, verbose = 2)\n",
    "    \n",
    "    # Fit the grid search to the data\n",
    "    grid_search_RF.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second one is training, testing and tuning the XGBoost regression. The values of grid might be updated regarding the problem (i.e., some problems might require higher values of n_estimators, while some might require lower ranges)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost parameter tuning\n",
      "Fitting 3 folds for each of 38880 candidates, totalling 116640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1832 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done 5080 tasks      | elapsed:   34.2s\n",
      "[Parallel(n_jobs=-1)]: Done 9608 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 15448 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 22568 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 31000 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 38912 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 49936 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 62240 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 75856 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done 81808 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 89692 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 98436 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done 107836 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done 116640 out of 116640 | elapsed: 15.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:07:12] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "#XGBoost Parameter Tuning------------------------------------------------------\n",
    "if XGboostparametertuning == \"yes\":\n",
    "    print(\"XGBoost parameter tuning\")\n",
    "    # Create the parameter grid based on the results of random search \n",
    "    grid = {'colsample_bytree': [0.9,0.8,0.7],\n",
    "                    'gamma': [2,3,4,5],\n",
    "                    'learning_rate': [0.1,0.2,0.3],\n",
    "                    'max_depth': [8,9,10,11,12],\n",
    "                    'n_estimators': [10,15,20,25],\n",
    "                    'subsample': [0.8,0.9,1],\n",
    "                    'reg_alpha': [15,16,17,18,19,20],\n",
    "                    'min_child_weight':[3,4,5]}\n",
    "\n",
    "    # Create a based model\n",
    "    XGB = XGBRegressor()\n",
    "    # Instantiate the grid search model\n",
    "    grid_search_XGB = GridSearchCV(estimator = XGB, param_grid = grid, \n",
    "                              cv = 3, n_jobs = -1, verbose = 2)\n",
    "    \n",
    "    # Fit the grid search to the data\n",
    "    grid_search_XGB.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third one is training, testing and tuning the SVM regression. The values of C_range or gamma_range might be updated regarding the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM parameter tuning\n",
      "Fitting 3 folds for each of 63 candidates, totalling 189 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 189 out of 189 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "#SVM Parameter Tuning----------------------------------------------------------\n",
    "if SVMparametertuning == \"yes\":\n",
    "    print(\"SVM parameter tuning\")\n",
    "\n",
    "    C_range = 10. ** np.arange(-3, 6)\n",
    "    gamma_range = 10. ** np.arange(-5, 2)\n",
    "    param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "    svr_rbf = SVR()\n",
    "    # Instantiate the grid search model\n",
    "    grid_search_svm = GridSearchCV(estimator = svr_rbf, param_grid = param_grid, \n",
    "                              cv = 3, n_jobs = -1, verbose = 2)\n",
    "    # Fit the grid search to the data\n",
    "    grid_search_svm.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fourth one is training, testing and tuning the MLP algorithm. The values of param_grid might be updated regarding the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM parameter tuning\n",
      "Fitting 3 folds for each of 360 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 222 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done 425 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 708 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1073 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  3.4min finished\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "if MLPparametertuning == \"yes\":\n",
    "    print(\"SVM parameter tuning\")\n",
    "\n",
    "    param_grid = {\n",
    "        'hidden_layer_sizes': [10,20,30,40,50,60,70,80,90,100],\n",
    "        'activation': ['identity','logistic','tanh','relu'],\n",
    "        'solver': ['lbfgs', 'sgd','adam'],\n",
    "        'learning_rate': ['constant','invscaling','adaptive']}\n",
    "    MLP = MLPRegressor()\n",
    "    # Instantiate the grid search model\n",
    "    grid_search_MLP = GridSearchCV(estimator = MLP, param_grid = param_grid, \n",
    "                              cv = 3, n_jobs = -1, verbose = 2)\n",
    "    \n",
    "    # Fit the grid search to the data\n",
    "    grid_search_MLP.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below commands provide a summary of the best parameters obtained from the GridSearch of all these four algortihms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search Best Parameters for Random Forest Regression\n",
      "{'bootstrap': True, 'max_depth': 50, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "Grid Search Best Parameters for XGBoost\n",
      "{'colsample_bytree': 0.9, 'gamma': 5, 'learning_rate': 0.2, 'max_depth': 11, 'min_child_weight': 5, 'n_estimators': 15, 'reg_alpha': 16, 'subsample': 0.8}\n",
      "Grid Search Best Parameters for SVM\n",
      "{'C': 1.0, 'gamma': 10.0}\n",
      "Grid Search Best Parameters for MLP\n",
      "{'activation': 'tanh', 'hidden_layer_sizes': 20, 'learning_rate': 'constant', 'solver': 'sgd'}\n"
     ]
    }
   ],
   "source": [
    "#Summary of the tuning parameters----------------------------------------------\n",
    "print(\"Grid Search Best Parameters for Random Forest Regression\")\n",
    "print (grid_search_RF.best_params_)\n",
    "print(\"Grid Search Best Parameters for XGBoost\")\n",
    "print (grid_search_XGB.best_params_)    \n",
    "print(\"Grid Search Best Parameters for SVM\")\n",
    "print (grid_search_svm.best_params_)\n",
    "print(\"Grid Search Best Parameters for MLP\")\n",
    "print (grid_search_MLP.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next thing, we will be fitting 9 different algortihms to our data to see which one performs the best. These are namely: multi linear regression, ridge regression, lasso regression, polynomial regression (degree=2), polynomial regression (degree=3), random forest regression (with the best parameters obtained from GridSearch), XGBoost regression (with the best parameters obtained from GridSearch), SVM regression (with the best parameters obtained from GridSearch) and MLP (with the best parameters obtained from GridSearch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit multilinear regression\n",
      "Fit ridge regression\n",
      "Fit Lasso regression\n",
      "Fit polynomial regression degree=2\n",
      "Fit polynomial regression degree=3\n",
      "Fit random forest regression\n",
      "Fit XGBoost regression\n",
      "[22:12:20] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fit SVR RBF regression\n",
      "Fit Multi-layer Perceptron regressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=20, learning_rate='constant',\n",
       "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "             power_t=0.5, random_state=None, shuffle=True, solver='sgd',\n",
       "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting multi linear regression to data---------------------------------------\n",
    "print (\"Fit multilinear regression\")\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train,y_train)\n",
    "\n",
    "#Fitting ridge regression to data----------------------------------------------\n",
    "print (\"Fit ridge regression\")\n",
    "ridgeReg = Ridge(alpha=0.05, normalize=True)\n",
    "ridgeReg.fit(X_train,y_train)\n",
    "\n",
    "#Fitting LASSO regression to data----------------------------------------------\n",
    "print (\"Fit Lasso regression\")\n",
    "lassoreg = Lasso(alpha=0.01, max_iter=10e5)\n",
    "lassoreg.fit(X_train, y_train)\n",
    "\n",
    "#Polynomial regression 2 degrees\n",
    "print (\"Fit polynomial regression degree=2\")\n",
    "poly2 = PolynomialFeatures(degree=2)\n",
    "X_train_trans = poly2.fit_transform(X_train)\n",
    "polyreg2 = linear_model.LinearRegression()\n",
    "p=polyreg2.fit(X_train_trans,y_train)\n",
    "poly2_coef = polyreg2.coef_\n",
    "\n",
    "#Polynomial regression 3 degrees\n",
    "print (\"Fit polynomial regression degree=3\")\n",
    "poly3 = PolynomialFeatures(degree=3)\n",
    "X_train_trans = poly3.fit_transform(X_train)\n",
    "polyreg3 = linear_model.LinearRegression()\n",
    "polyreg3.fit(X_train_trans,y_train)\n",
    "poly3_coef = polyreg3.coef_\n",
    "\n",
    "#Fitting random forest regression to data--------------------------------------\n",
    "print (\"Fit random forest regression\")\n",
    "randreg = RandomForestRegressor(**grid_search_RF.best_params_)\n",
    "randreg.fit(X_train2,y_train2)\n",
    "\n",
    "#Fitting XGboost regression to data--------------------------------------------\n",
    "print (\"Fit XGBoost regression\")\n",
    "XGBreg = XGBRegressor(**grid_search_XGB.best_params_)\n",
    "XGBreg.fit(X_train2, y_train2)\n",
    "\n",
    "#Support Vector Machines-------------------------------------------------------\n",
    "svr_rbf = SVR(**grid_search_svm.best_params_)\n",
    "print (\"Fit SVR RBF regression\")\n",
    "svr_rbf.fit(X_train2, y_train2)\n",
    "\n",
    "#MLP Regressor-----------------------------------------------------------------\n",
    "MLP = MLPRegressor(**grid_search_MLP.best_params_)\n",
    "print (\"Fit Multi-layer Perceptron regressor\")\n",
    "MLP.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the error analysis, we are using four different statistics. The first one is r_score, which is the r2 (coefficient of determination) of the test data and the predicted data. The second is MAE = Mean Absolute Error, the third one is MSE = Mean Squared Error and the third one is MAPE = Mean Absolute Percentage Error. The MAE and MSE calculations come directly from sklearn.metrics / mean_absolute_error and mean_squared_error. For the r_score and MAPE, we are defining below functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the missing sklearn.metrics parameter of mean absolute percentage error\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return (np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def r_score(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    residuals = y_true- y_pred\n",
    "    ss_res = np.sum(residuals**2)\n",
    "    ss_tot = np.sum((y_true-np.mean(y_true))**2)\n",
    "    r_squared = 1 - (ss_res / ss_tot)    \n",
    "    return r_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the error statistics are defined, lets predict the predicted values by the algorithm and calculate the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "y_predicted_RF = randreg.predict(X_test2)\n",
    "y_predicted_LREG = linreg.predict(X_test)\n",
    "y_predicted_RIDGE = ridgeReg.predict(X_test)\n",
    "y_predicted_XGB = XGBreg.predict(X_test2)\n",
    "y_predicted_LASSO = lassoreg.predict(X_test)\n",
    "y_predicted_svr_rbf = svr_rbf.predict(X_test2)\n",
    "y_predicted_MLP = MLP.predict(X_test2)\n",
    "y_predicted_PREG2 = polyreg2.predict(poly2.fit_transform(X_test))\n",
    "y_predicted_PREG3 = polyreg3.predict(poly3.fit_transform(X_test))\n",
    "\n",
    "r_RF=  r_score(y_test2, y_predicted_RF)\n",
    "MAE_RF = mean_absolute_error(y_test2, y_predicted_RF)\n",
    "MSE_RF = mean_squared_error(y_test2, y_predicted_RF)\n",
    "MAPE_RF = mean_absolute_percentage_error(y_test2, y_predicted_RF)\n",
    "\n",
    "r_LREG=  r_score(y_test, y_predicted_LREG)\n",
    "MAE_LREG = mean_absolute_error(y_test, y_predicted_LREG)\n",
    "MSE_LREG = mean_squared_error(y_test, y_predicted_LREG)\n",
    "MAPE_LREG = mean_absolute_percentage_error(y_test, y_predicted_LREG)\n",
    "\n",
    "r_RIDGE=  r_score(y_test, y_predicted_RIDGE)\n",
    "MAE_RIDGE = mean_absolute_error(y_test, y_predicted_RIDGE)\n",
    "MSE_RIDGE = mean_squared_error(y_test, y_predicted_RIDGE)\n",
    "MAPE_RIDGE = mean_absolute_percentage_error(y_test, y_predicted_RIDGE)\n",
    "\n",
    "r_XGB=  r_score(y_test2, y_predicted_XGB)\n",
    "MAE_XGB = mean_absolute_error(y_test2, y_predicted_XGB)\n",
    "MSE_XGB = mean_squared_error(y_test2, y_predicted_XGB)\n",
    "MAPE_XGB = mean_absolute_percentage_error(y_test2, y_predicted_XGB)\n",
    "\n",
    "r_LASSO=  r_score(y_test, y_predicted_LASSO)\n",
    "MAE_LASSO = mean_absolute_error(y_test, y_predicted_LASSO)\n",
    "MSE_LASSO = mean_squared_error(y_test, y_predicted_LASSO)\n",
    "MAPE_LASSO = mean_absolute_percentage_error(y_test, y_predicted_LASSO)\n",
    "\n",
    "r_svr_rbf=  r_score(y_test2, y_predicted_svr_rbf)\n",
    "MAE_svr_rbf = mean_absolute_error(y_test2, y_predicted_svr_rbf)\n",
    "MSE_svr_rbf = mean_squared_error(y_test2, y_predicted_svr_rbf)\n",
    "MAPE_svr_rbf = mean_absolute_percentage_error(y_test2, y_predicted_svr_rbf)\n",
    "\n",
    "r_MLP=  r_score(y_test2, y_predicted_MLP)\n",
    "MAE_MLP = mean_absolute_error(y_test2, y_predicted_MLP)\n",
    "MSE_MLP = mean_squared_error(y_test2, y_predicted_MLP)\n",
    "MAPE_MLP = mean_absolute_percentage_error(y_test2, y_predicted_MLP)\n",
    "\n",
    "r_PREG2= r_score(y_test, y_predicted_PREG2)\n",
    "MAE_PREG2= mean_absolute_error(y_test, y_predicted_PREG2)\n",
    "MSE_PREG2= mean_squared_error(y_test, y_predicted_PREG2)\n",
    "MAPE_PREG2= np.mean(mean_absolute_percentage_error(y_test, y_predicted_PREG2))\n",
    "\n",
    "r_PREG3= r_score(y_test, y_predicted_PREG3)\n",
    "MAE_PREG3= mean_absolute_error(y_test, y_predicted_PREG3)\n",
    "MSE_PREG3= mean_squared_error(y_test, y_predicted_PREG3)\n",
    "MAPE_PREG3= np.mean(mean_absolute_percentage_error(y_test, y_predicted_PREG3))\n",
    "\n",
    "errors = [{'Model Name': 'Random Forest Regression', 'R2': r_RF, 'MAE': MAE_RF, 'MSE': MSE_RF, 'MAPE (%)': np.mean(MAPE_RF), 'Median Error (%)': statistics.median(MAPE_RF)},\n",
    "          {'Model Name': 'Linear Regression', 'R2': r_LREG, 'MAE': MAE_LREG, 'MSE': MSE_LREG, 'MAPE (%)': np.mean(MAPE_LREG), 'Median Error (%)': statistics.median(MAPE_LREG)},\n",
    "          {'Model Name': 'Ridge Regression', 'R2': r_RIDGE, 'MAE': MAE_RIDGE, 'MSE': MSE_RIDGE, 'MAPE (%)': np.mean(MAPE_RIDGE), 'Median Error (%)': statistics.median(MAPE_RIDGE)},\n",
    "          {'Model Name': 'XGBoost Regression', 'R2': r_XGB, 'MAE': MAE_XGB, 'MSE': MSE_XGB, 'MAPE (%)': np.mean(MAPE_XGB), 'Median Error (%)': statistics.median(MAPE_XGB)},\n",
    "          {'Model Name': 'Lasso Regression', 'R2': r_LASSO, 'MAE': MAE_LASSO, 'MSE': MSE_LASSO, 'MAPE (%)': np.mean(MAPE_LASSO), 'Median Error (%)': statistics.median(MAPE_LASSO)},\n",
    "          {'Model Name': 'Support Vector Machine', 'R2': r_svr_rbf, 'MAE': MAE_svr_rbf, 'MSE': MSE_svr_rbf, 'MAPE (%)': np.mean(MAPE_svr_rbf), 'Median Error (%)': statistics.median(MAPE_svr_rbf)},\n",
    "          {'Model Name': 'Multi-layer Perceptron', 'R2': r_MLP, 'MAE': MAE_MLP, 'MSE': MSE_MLP, 'MAPE (%)': np.mean(MAPE_MLP), 'Median Error (%)': statistics.median(MAPE_MLP)},\n",
    "          {'Model Name': '2nd Polynomial Regression', 'R2': r_PREG2 , 'MAE': MAE_PREG2 , 'MSE': MSE_PREG2 , 'MAPE (%)': MAPE_PREG2},\n",
    "          {'Model Name': '3rd Polynomial Regression', 'R2': r_PREG3 , 'MAE': MAE_PREG3 , 'MSE': MSE_PREG3 , 'MAPE (%)': MAPE_PREG3}]\n",
    "\n",
    "df_estimationerrors = pd.DataFrame(errors)\n",
    "df_estimationerrors= df_estimationerrors.sort_values(by=['Median Error (%)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how our error table looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Model Name        R2        MAE         MSE  MAPE (%)  \\\n",
      "1          Linear Regression -0.020588  12.053405  201.081182       inf   \n",
      "4           Lasso Regression -0.020576  12.053432  201.078812       inf   \n",
      "2           Ridge Regression -0.019932  12.052451  200.951796       inf   \n",
      "6     Multi-layer Perceptron -0.033154  13.295343  235.210240       inf   \n",
      "0   Random Forest Regression -0.112244  13.626612  253.216151       inf   \n",
      "5     Support Vector Machine -0.017291  13.176381  231.599012       inf   \n",
      "3         XGBoost Regression -0.134958  13.669333  258.387192       inf   \n",
      "7  2nd Polynomial Regression -0.016995  12.045494  200.373243       inf   \n",
      "8  3rd Polynomial Regression  0.008126  11.821172  195.423782       inf   \n",
      "\n",
      "   Median Error (%)  \n",
      "1         39.029110  \n",
      "4         39.031660  \n",
      "2         39.084200  \n",
      "6         42.218712  \n",
      "0         43.739991  \n",
      "5         44.800299  \n",
      "3         45.744380  \n",
      "7               NaN  \n",
      "8               NaN  \n"
     ]
    }
   ],
   "source": [
    "print(df_estimationerrors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize our erros by BoxPlots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py:3942: RuntimeWarning: invalid value encountered in multiply\n",
      "  x2 = take(ap, indices_above, axis=axis) * weights_above\n",
      "/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py:3942: RuntimeWarning: invalid value encountered in multiply\n",
      "  x2 = take(ap, indices_above, axis=axis) * weights_above\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Boxplot \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Create a figure instance\n",
    "fig = plt.figure(1, figsize=(9, 6))\n",
    "\n",
    "# Create an axes instance\n",
    "ax = fig.add_subplot(111)\n",
    "data_to_plot = [MAPE_RF,MAPE_MLP,MAPE_svr_rbf,MAPE_XGB,MAPE_RIDGE,MAPE_LASSO,MAPE_LREG,MAPE_PREG2,MAPE_PREG3]\n",
    "\n",
    "# Create the boxplot\n",
    "bp = ax.boxplot(data_to_plot)\n",
    "## add patch_artist=True option to ax.boxplot() \n",
    "## to get fill color\n",
    "bp = ax.boxplot(data_to_plot, patch_artist=True)\n",
    "\n",
    "## change outline color, fill color and linewidth of the boxes\n",
    "for box in bp['boxes']:\n",
    "    # change outline color\n",
    "    box.set( color='#7570b3', linewidth=2)\n",
    "    # change fill color\n",
    "    box.set( facecolor = '#1b9e77' )\n",
    "\n",
    "## change color and linewidth of the whiskers\n",
    "for whisker in bp['whiskers']:\n",
    "    whisker.set(color='#7570b3', linewidth=2)\n",
    "\n",
    "## change color and linewidth of the caps\n",
    "for cap in bp['caps']:\n",
    "    cap.set(color='#7570b3', linewidth=2)\n",
    "\n",
    "## change color and linewidth of the medians\n",
    "for median in bp['medians']:\n",
    "    median.set(color='#b2df8a', linewidth=2)\n",
    "\n",
    "## change the style of fliers and their fill\n",
    "for flier in bp['fliers']:\n",
    "    flier.set(marker='o', color='#e7298a', alpha=0.5)\n",
    "              \n",
    "## Custom x-axis labels\n",
    "ax.set_xticklabels(['Random Forest',  'MLP','SVM', 'XGBoost','Ridge','Lasso','Multi Linear','Polynomial 2','Polynomial 3'])\n",
    "ax.set_ylim(0,100)\n",
    "ax.set_ylabel(\"Percentage Error (%)\")\n",
    "## Remove top axes and right axes ticks\n",
    "ax.get_xaxis().tick_bottom()\n",
    "ax.get_yaxis().tick_left()\n",
    "\n",
    "fig.savefig('boxplots.png', dpi=1000)\n",
    "fig.savefig('boxplots.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, perform a principal component analysis (PCA) using the random forest regression results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Principal Component Analysis\n",
    "features = df.columns[:-1]\n",
    "importances = randreg.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "plt.figure(3) #the axis number\n",
    "plt.title('Feature Importance')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), features[indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.savefig('Feature Importance.png', \n",
    "              bbox_inches='tight', dpi = 500,figsize=(8,6))\n",
    "\n",
    "df_estimationerrors.to_csv(\"errors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
