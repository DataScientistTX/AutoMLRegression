{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explains the steps to develop an Automated Supervised Machine Learning Regression program, which automatically tunes the hyperparameters and prints out the final accuracy results as a tables together with feature importance results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import all libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import max_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_poisson_deviance\n",
    "from sklearn.metrics import mean_gamma_deviance\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "from itertools import repeat\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets import our dataset from the csv files as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at dataset. I like using df.describe() function to have some statistics about each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the features as X and the column we want to predict (column F) as y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df.columns)\n",
    "X = df.iloc[:,0:n-1].to_numpy() \n",
    "y = df.iloc[:,n-1].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines X as all the values except the last column (columns A,B,C,D,E), and y as the last column (column numbers start from zero, hence: 0 - A, 1 - B, 2 - C, 3 - D,4 - E, 5 -F)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some algorithms provide better accuracies with the standard scaling of the input features (i.e. normalization). Let's normalize the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X= scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to split our dataset as train and test data. For this we can use train_test_split by sklearn.model_selection. Test size of 0.20 means that 20% of the data will be used as test data and 80% of the data will be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X,y,test_size = 0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might not always want to tune the parameters of models, or only tune for some models. For this I have defined a basic input. When it is set to \"True\", the program will perform the tuning for all the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Perform_tuning = True\n",
    "Lassotuning, Ridgetuning, randomforestparametertuning, XGboostparametertuning, SVMparametertuning, MLPparametertuning = repeat(Perform_tuning,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the grid search function to be used with our models. The values of grid might need to be changed regarding the problem (i.e., some problems might require higher values of n_estimators, while some might require lower ranges)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(model,grid):\n",
    "    # Instantiate the grid search model\n",
    "    print (\"Performing gridsearch for {}\".format(model))\n",
    "    grid_search = GridSearchCV(estimator = model(), param_grid=grid, \n",
    "                              cv = 3, n_jobs = -1, verbose = 2)\n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"Grid Search Best Parameters for {}\".format(model))\n",
    "    print (grid_search.best_params_)\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Lasso parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Lassotuning:\n",
    "    # Create the parameter grid based on the results of random search \n",
    "    grid = {\n",
    "        'alpha': [1,0.9,0.75,0.5,0.1,0.01,0.001,0.0001] , \n",
    "        \"fit_intercept\": [True, False]\n",
    "    }\n",
    "    Lasso_bestparam = grid_search(Lasso,grid) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Ridge parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Ridgetuning:\n",
    "    # Create the parameter grid based on the results of random search \n",
    "    grid = {\n",
    "        'alpha': [1,0.9,0.75,0.5,0.1,0.01,0.001,0.0001] , \n",
    "        \"fit_intercept\": [True, False]\n",
    "    }\n",
    "    Ridge_bestparam = grid_search(Ridge,grid) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Random Forest parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if randomforestparametertuning:\n",
    "    # Create the parameter grid based on the results of random search \n",
    "    grid = {\n",
    "        'bootstrap': [True,False],\n",
    "        'max_depth': [40, 50, 60, 70],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'min_samples_leaf': [1,2,3,],\n",
    "        'min_samples_split': [3, 4, 5,6,7],\n",
    "        'n_estimators': [5,10,15]\n",
    "        }\n",
    "    RF_bestparam = grid_search(RandomForestRegressor,grid) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing XGBoost parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if XGboostparametertuning:\n",
    "    # Create the parameter grid based on the results of random search \n",
    "    grid = {'colsample_bytree': [0.9,0.7],\n",
    "                    'gamma': [2,5],\n",
    "                    'learning_rate': [0.1,0.2,0.3],\n",
    "                    'max_depth': [8,10,12],\n",
    "                    'n_estimators': [5,10],\n",
    "                    'subsample': [0.8,1],\n",
    "                    'reg_alpha': [15,20],\n",
    "                    'min_child_weight':[3,5]}\n",
    "    XGB_bestparam = grid_search(XGBRegressor,grid) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing SVM parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM Parameter Tuning----------------------------------------------------------\n",
    "if SVMparametertuning:\n",
    "    grid = {'gamma': 10. ** np.arange(-5, 3),\n",
    "            'C': 10. ** np.arange(-3, 3)}\n",
    "    SVR_bestparam = grid_search(SVR,grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing MLP parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MLPparametertuning:\n",
    "    grid = {\n",
    "        'hidden_layer_sizes': [2,5,8,10],\n",
    "        'activation': ['identity','logistic','tanh','relu'],\n",
    "        'solver': ['lbfgs', 'sgd','adam'],\n",
    "        'learning_rate': ['constant','invscaling','adaptive']}\n",
    "    MLP_bestparam = grid_search(MLPRegressor,grid)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we obtained the best parameters for all the models using the training data. Let's define the error metrics that will be used in analyzing the accuracy of each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_metrics = (\n",
    "    explained_variance_score,\n",
    "    max_error,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    mean_squared_log_error,\n",
    "    median_absolute_error,\n",
    "    r2_score,\n",
    "    mean_poisson_deviance,\n",
    "    mean_gamma_deviance,\n",
    "    mean_absolute_percentage_error        \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define fit_model function to predict the results, and analyze the error metrics for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model,X_train, X_test, y_train, y_test,error_metrics):\n",
    "    fitted_model = model.fit(X_train,y_train)\n",
    "    y_predicted = fitted_model.predict(X_test)\n",
    "    calculations = []\n",
    "    for metric in error_metrics:\n",
    "        calc = metric(y_test, y_predicted)\n",
    "        calculations.append(calc)\n",
    "    return calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide a summary of each model and their GridSearch best parameter results. If tuning is not performed, the script will use the default values as best parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    trainingmodels = (\n",
    "        LinearRegression(), \n",
    "        Ridge(**Ridge_bestparam), \n",
    "        RandomForestRegressor(**RF_bestparam), \n",
    "        XGBRegressor(**XGB_bestparam), \n",
    "        Lasso(**Lasso_bestparam),\n",
    "        SVR(**SVR_bestparam),\n",
    "        MLPRegressor(**MLP_bestparam)\n",
    "    )\n",
    "    \n",
    "except:\n",
    "    trainingmodels = (\n",
    "        LinearRegression(), \n",
    "        Ridge(), \n",
    "        RandomForestRegressor(), \n",
    "        XGBRegressor(), \n",
    "        Lasso(),\n",
    "        SVR(),\n",
    "        MLPRegressor()\n",
    "    )    \n",
    "\n",
    "calculations = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below loop performes training, testing and error metrics calculations for each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trainmodel in trainingmodels:\n",
    "    errors = fit_model(trainmodel,X_train, X_test, y_train, y_test,error_metrics)\n",
    "    calculations.append(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's organize these results, and summarize them all in a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = (\n",
    "    'Explained variance score',\n",
    "    'Max error',\n",
    "    'Mean  absolute error',\n",
    "    'Mean squared error',\n",
    "    'Mean squared log error',\n",
    "    'Median absolute error',\n",
    "    'r2 score',\n",
    "    'Mean poisson deviance',\n",
    "    'Mean gamma deviance',\n",
    "    'Mean absolute percentage error'        \n",
    ")\n",
    "\n",
    "model_names = (\n",
    "    'LinearRegression', \n",
    "    'Ridge', \n",
    "    'RandomForestRegressor', \n",
    "    'XGBRegressor', \n",
    "    'Lasso',\n",
    "    'SVR',\n",
    "    'MLPRegressor'\n",
    ")\n",
    "\n",
    "df_error = pd.DataFrame(calculations, columns=errors)\n",
    "df_error[\"Model\"] = model_names\n",
    "\n",
    "cols = df_error.columns.tolist() \n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df_error = df_error[cols]\n",
    "df_error = df_error.sort_values(by=['Mean squared error'],ascending=True)\n",
    "df_error = (df_error.set_index('Model')\n",
    "        .astype(float)\n",
    "        .applymap('{:,.3f}'.format))\n",
    "df_error.to_csv(\"errors.csv\")\n",
    "df_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we can analyze the feature importance results using the Random Forest regressor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Principal Component Analysis\n",
    "features = df.columns[:-1]\n",
    "try:\n",
    "    randreg = RandomForestRegressor(**RF_bestparam).fit(X,y)\n",
    "except:\n",
    "    randreg = RandomForestRegressor().fit(X,y)    \n",
    "importances = randreg.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "plt.figure(3) #the axis number\n",
    "plt.title('Feature Importance')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), features[indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.savefig('Feature Importance.png', \n",
    "              bbox_inches='tight', dpi = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
