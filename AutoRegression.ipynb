{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explains the steps to develop an Automated Supervised Machine Learning Regression program, which automatically tunes the hyperparameters and prints out the final accuracy results as a tables together with feature importance results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import all libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import max_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_poisson_deviance\n",
    "from sklearn.metrics import mean_gamma_deviance\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "from itertools import repeat\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets import our dataset from the csv files as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at dataset. I like using df.describe() function to have some statistics about each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>27.0</td>\n",
       "      <td>12.438889</td>\n",
       "      <td>0.181518</td>\n",
       "      <td>12.050000</td>\n",
       "      <td>12.350000</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>12.525000</td>\n",
       "      <td>12.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>27.0</td>\n",
       "      <td>13.240741</td>\n",
       "      <td>1.476550</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>27.0</td>\n",
       "      <td>722.518519</td>\n",
       "      <td>124.861884</td>\n",
       "      <td>496.000000</td>\n",
       "      <td>632.500000</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>885.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>27.0</td>\n",
       "      <td>19.259259</td>\n",
       "      <td>1.631248</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>27.0</td>\n",
       "      <td>12.296296</td>\n",
       "      <td>2.267069</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>27.0</td>\n",
       "      <td>68.832028</td>\n",
       "      <td>13.160644</td>\n",
       "      <td>40.321912</td>\n",
       "      <td>59.554258</td>\n",
       "      <td>66.549069</td>\n",
       "      <td>81.377992</td>\n",
       "      <td>92.415572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count        mean         std         min         25%         50%  \\\n",
       "A   27.0   12.438889    0.181518   12.050000   12.350000   12.400000   \n",
       "B   27.0   13.240741    1.476550   11.500000   12.000000   13.000000   \n",
       "C   27.0  722.518519  124.861884  496.000000  632.500000  720.000000   \n",
       "D   27.0   19.259259    1.631248   16.000000   18.000000   19.000000   \n",
       "E   27.0   12.296296    2.267069    9.000000   11.000000   12.000000   \n",
       "F   27.0   68.832028   13.160644   40.321912   59.554258   66.549069   \n",
       "\n",
       "          75%         max  \n",
       "A   12.525000   12.800000  \n",
       "B   14.250000   17.000000  \n",
       "C  832.000000  885.000000  \n",
       "D   20.000000   23.000000  \n",
       "E   14.000000   18.000000  \n",
       "F   81.377992   92.415572  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the features as X and the column we want to predict (column F) as y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df.columns)\n",
    "X = df.iloc[:,0:n-1].to_numpy() \n",
    "y = df.iloc[:,n-1].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines X as all the values except the last column (columns A,B,C,D,E), and y as the last column (column numbers start from zero, hence: 0 - A, 1 - B, 2 - C, 3 - D,4 - E, 5 -F)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some algorithms provide better accuracies with the standard scaling of the input features (i.e. normalization). Let's normalize the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X= scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to split our dataset as train and test data. For this we can use train_test_split by sklearn.model_selection. Test size of 0.20 means that 20% of the data will be used as test data and 80% of the data will be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X,y,test_size = 0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might not always want to tune the parameters of models, or only tune for some models. For this I have defined a basic input. When it is set to \"True\", the program will perform the tuning for all the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Perform_tuning = True\n",
    "Lassotuning, Ridgetuning, randomforestparametertuning, XGboostparametertuning, SVMparametertuning, MLPparametertuning = repeat(Perform_tuning,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the grid search function to be used with our models. The values of grid might need to be changed regarding the problem (i.e., some problems might require higher values of n_estimators, while some might require lower ranges)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(model,grid):\n",
    "    # Instantiate the grid search model\n",
    "    print (\"Performing gridsearch for {}\".format(model))\n",
    "    grid_search = GridSearchCV(estimator = model(), param_grid=grid, \n",
    "                              cv = 3, n_jobs = -1, verbose = 2)\n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"Grid Search Best Parameters for {}\".format(model))\n",
    "    print (grid_search.best_params_)\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Lasso parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing gridsearch for <class 'sklearn.linear_model._coordinate_descent.Lasso'>\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Grid Search Best Parameters for <class 'sklearn.linear_model._coordinate_descent.Lasso'>\n",
      "{'alpha': 0.1, 'fit_intercept': True}\n"
     ]
    }
   ],
   "source": [
    "if Lassotuning:\n",
    "    # Create the parameter grid based on the results of random search \n",
    "    grid = {\n",
    "        'alpha': [1,0.9,0.75,0.5,0.1,0.01,0.001,0.0001] , \n",
    "        \"fit_intercept\": [True, False]\n",
    "    }\n",
    "    Lasso_bestparam = grid_search(Lasso,grid) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Ridge parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing gridsearch for <class 'sklearn.linear_model._ridge.Ridge'>\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Grid Search Best Parameters for <class 'sklearn.linear_model._ridge.Ridge'>\n",
      "{'alpha': 0.5, 'fit_intercept': True}\n"
     ]
    }
   ],
   "source": [
    "if Ridgetuning:\n",
    "    # Create the parameter grid based on the results of random search \n",
    "    grid = {\n",
    "        'alpha': [1,0.9,0.75,0.5,0.1,0.01,0.001,0.0001] , \n",
    "        \"fit_intercept\": [True, False]\n",
    "    }\n",
    "    Ridge_bestparam = grid_search(Ridge,grid) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Random Forest parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing gridsearch for <class 'sklearn.ensemble._forest.RandomForestRegressor'>\n",
      "Fitting 3 folds for each of 720 candidates, totalling 2160 fits\n",
      "Grid Search Best Parameters for <class 'sklearn.ensemble._forest.RandomForestRegressor'>\n",
      "{'bootstrap': True, 'max_depth': 60, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 15}\n"
     ]
    }
   ],
   "source": [
    "if randomforestparametertuning:\n",
    "    # Create the parameter grid based on the results of random search \n",
    "    grid = {\n",
    "        'bootstrap': [True,False],\n",
    "        'max_depth': [40, 50, 60, 70],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'min_samples_leaf': [1,2,3,],\n",
    "        'min_samples_split': [3, 4, 5,6,7],\n",
    "        'n_estimators': [5,10,15]\n",
    "        }\n",
    "    RF_bestparam = grid_search(RandomForestRegressor,grid) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing XGBoost parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing gridsearch for <class 'xgboost.sklearn.XGBRegressor'>\n",
      "Fitting 3 folds for each of 576 candidates, totalling 1728 fits\n",
      "Grid Search Best Parameters for <class 'xgboost.sklearn.XGBRegressor'>\n",
      "{'colsample_bytree': 0.9, 'gamma': 5, 'learning_rate': 0.3, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 10, 'reg_alpha': 15, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "if XGboostparametertuning:\n",
    "    # Create the parameter grid based on the results of random search \n",
    "    grid = {'colsample_bytree': [0.9,0.7],\n",
    "                    'gamma': [2,5],\n",
    "                    'learning_rate': [0.1,0.2,0.3],\n",
    "                    'max_depth': [8,10,12],\n",
    "                    'n_estimators': [5,10],\n",
    "                    'subsample': [0.8,1],\n",
    "                    'reg_alpha': [15,20],\n",
    "                    'min_child_weight':[3,5]}\n",
    "    XGB_bestparam = grid_search(XGBRegressor,grid) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing SVM parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing gridsearch for <class 'sklearn.svm._classes.SVR'>\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Grid Search Best Parameters for <class 'sklearn.svm._classes.SVR'>\n",
      "{'C': 100.0, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "#SVM Parameter Tuning----------------------------------------------------------\n",
    "if SVMparametertuning:\n",
    "    grid = {'gamma': 10. ** np.arange(-5, 3),\n",
    "            'C': 10. ** np.arange(-3, 3)}\n",
    "    SVR_bestparam = grid_search(SVR,grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing MLP parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing gridsearch for <class 'sklearn.neural_network._multilayer_perceptron.MLPRegressor'>\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "Grid Search Best Parameters for <class 'sklearn.neural_network._multilayer_perceptron.MLPRegressor'>\n",
      "{'activation': 'relu', 'hidden_layer_sizes': 8, 'learning_rate': 'constant', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "if MLPparametertuning:\n",
    "    grid = {\n",
    "        'hidden_layer_sizes': [2,5,8,10],\n",
    "        'activation': ['identity','logistic','tanh','relu'],\n",
    "        'solver': ['lbfgs', 'sgd','adam'],\n",
    "        'learning_rate': ['constant','invscaling','adaptive']}\n",
    "    MLP_bestparam = grid_search(MLPRegressor,grid)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we obtained the best parameters for all the models using the training data. Let's define the error metrics that will be used in analyzing the accuracy of each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_metrics = (\n",
    "    explained_variance_score,\n",
    "    max_error,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    mean_squared_log_error,\n",
    "    median_absolute_error,\n",
    "    r2_score,\n",
    "    mean_poisson_deviance,\n",
    "    mean_gamma_deviance,\n",
    "    mean_absolute_percentage_error        \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define fit_model function to predict the results, and analyze the error metrics for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model,X_train, X_test, y_train, y_test,error_metrics):\n",
    "    fitted_model = model.fit(X_train,y_train)\n",
    "    y_predicted = fitted_model.predict(X_test)\n",
    "    calculations = []\n",
    "    for metric in error_metrics:\n",
    "        calc = metric(y_test, y_predicted)\n",
    "        calculations.append(calc)\n",
    "    return calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide a summary of each model and their GridSearch best parameter results. If tuning is not performed, the script will use the default values as best parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    trainingmodels = (\n",
    "        LinearRegression(), \n",
    "        Ridge(**Ridge_bestparam), \n",
    "        RandomForestRegressor(**RF_bestparam), \n",
    "        XGBRegressor(**XGB_bestparam), \n",
    "        Lasso(**Lasso_bestparam),\n",
    "        SVR(**SVR_bestparam),\n",
    "        MLPRegressor(**MLP_bestparam)\n",
    "    )\n",
    "    \n",
    "except:\n",
    "    trainingmodels = (\n",
    "        LinearRegression(), \n",
    "        Ridge(), \n",
    "        RandomForestRegressor(), \n",
    "        XGBRegressor(), \n",
    "        Lasso(),\n",
    "        SVR(),\n",
    "        MLPRegressor()\n",
    "    )    \n",
    "\n",
    "calculations = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below loop performes training, testing and error metrics calculations for each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trainmodel in trainingmodels:\n",
    "    errors = fit_model(trainmodel,X_train, X_test, y_train, y_test,error_metrics)\n",
    "    calculations.append(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's organize these results, and summarize them all in a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Explained variance score</th>\n",
       "      <th>Max error</th>\n",
       "      <th>Mean  absolute error</th>\n",
       "      <th>Mean squared error</th>\n",
       "      <th>Mean squared log error</th>\n",
       "      <th>Median absolute error</th>\n",
       "      <th>r2 score</th>\n",
       "      <th>Mean poisson deviance</th>\n",
       "      <th>Mean gamma deviance</th>\n",
       "      <th>Mean absolute percentage error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.998</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.997</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.995</td>\n",
       "      <td>1.180</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.931</td>\n",
       "      <td>5.460</td>\n",
       "      <td>1.771</td>\n",
       "      <td>6.871</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.875</td>\n",
       "      <td>5.233</td>\n",
       "      <td>2.555</td>\n",
       "      <td>9.634</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2.735</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.939</td>\n",
       "      <td>7.474</td>\n",
       "      <td>4.334</td>\n",
       "      <td>23.491</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3.405</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Explained variance score Max error Mean  absolute error  \\\n",
       "Model                                                                           \n",
       "LinearRegression                         0.998     0.647                0.314   \n",
       "Lasso                                    0.999     0.744                0.327   \n",
       "Ridge                                    0.997     0.731                0.412   \n",
       "SVR                                      0.995     1.180                0.497   \n",
       "MLPRegressor                             0.931     5.460                1.771   \n",
       "RandomForestRegressor                    0.875     5.233                2.555   \n",
       "XGBRegressor                             0.939     7.474                4.334   \n",
       "\n",
       "                      Mean squared error Mean squared log error  \\\n",
       "Model                                                             \n",
       "LinearRegression                   0.143                  0.000   \n",
       "Lasso                              0.145                  0.000   \n",
       "Ridge                              0.243                  0.000   \n",
       "SVR                                0.479                  0.000   \n",
       "MLPRegressor                       6.871                  0.002   \n",
       "RandomForestRegressor              9.634                  0.002   \n",
       "XGBRegressor                      23.491                  0.005   \n",
       "\n",
       "                      Median absolute error r2 score Mean poisson deviance  \\\n",
       "Model                                                                        \n",
       "LinearRegression                      0.255    0.998                 0.002   \n",
       "Lasso                                 0.291    0.998                 0.002   \n",
       "Ridge                                 0.520    0.997                 0.004   \n",
       "SVR                                   0.207    0.994                 0.008   \n",
       "MLPRegressor                          0.803    0.911                 0.112   \n",
       "RandomForestRegressor                 2.735    0.875                 0.149   \n",
       "XGBRegressor                          3.405    0.696                 0.363   \n",
       "\n",
       "                      Mean gamma deviance Mean absolute percentage error  \n",
       "Model                                                                     \n",
       "LinearRegression                    0.000                          0.005  \n",
       "Lasso                               0.000                          0.005  \n",
       "Ridge                               0.000                          0.007  \n",
       "SVR                                 0.000                          0.008  \n",
       "MLPRegressor                        0.002                          0.030  \n",
       "RandomForestRegressor               0.002                          0.040  \n",
       "XGBRegressor                        0.006                          0.066  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = (\n",
    "    'Explained variance score',\n",
    "    'Max error',\n",
    "    'Mean  absolute error',\n",
    "    'Mean squared error',\n",
    "    'Mean squared log error',\n",
    "    'Median absolute error',\n",
    "    'r2 score',\n",
    "    'Mean poisson deviance',\n",
    "    'Mean gamma deviance',\n",
    "    'Mean absolute percentage error'        \n",
    ")\n",
    "\n",
    "model_names = (\n",
    "    'LinearRegression', \n",
    "    'Ridge', \n",
    "    'RandomForestRegressor', \n",
    "    'XGBRegressor', \n",
    "    'Lasso',\n",
    "    'SVR',\n",
    "    'MLPRegressor'\n",
    ")\n",
    "\n",
    "df_error = pd.DataFrame(calculations, columns=errors)\n",
    "df_error[\"Model\"] = model_names\n",
    "\n",
    "cols = df_error.columns.tolist() \n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df_error = df_error[cols]\n",
    "df_error = df_error.sort_values(by=['Mean squared error'],ascending=True)\n",
    "df_error = (df_error.set_index('Model')\n",
    "        .astype(float)\n",
    "        .applymap('{:,.3f}'.format))\n",
    "df_error.to_csv(\"errors.csv\")\n",
    "df_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we can analyze the feature importance results using the Random Forest regressor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Principal Component Analysis\n",
    "features = df.columns[:-1]\n",
    "try:\n",
    "    randreg = RandomForestRegressor(**RF_bestparam).fit(X,y)\n",
    "except:\n",
    "    randreg = RandomForestRegressor().fit(X,y)    \n",
    "importances = randreg.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "plt.figure(3) #the axis number\n",
    "plt.title('Feature Importance')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), features[indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.savefig('Feature Importance.png', \n",
    "              bbox_inches='tight', dpi = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
